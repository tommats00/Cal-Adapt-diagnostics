{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9687c898-2f0a-4842-952a-baf12c7b83b4",
   "metadata": {},
   "source": [
    "# Mapping Multiple Variables: Cal-Adapt\n",
    "### Authors\n",
    "\n",
    "Samantha Stevenson sstevenson@ucsb.edu\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Goals](#purpose)\n",
    "\n",
    "[Import Packages](#path)\n",
    "\n",
    "[Load and Query the Cal-Adapt Catalog](#load)\n",
    "\n",
    "[Read in Data](#xarray)\n",
    "\n",
    "[Make Maps](#maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4dc47-5284-4465-b599-cef6bab9280c",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "## **Goals**\n",
    "\n",
    "In this tutorial, we will continue working with the [Cal-Adapt Analytics Engine Data Catalog](https://analytics.cal-adapt.org/data/catalog/), to visualize multiple geospatial data fields on the same plot!\n",
    "\n",
    "Skills provided in this tutorial:\n",
    "- Mapping, including displaying geospatial features using shape files;\n",
    "- Using **vector** plots to display multiple variables on a map at once!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907ddd9-f286-45b1-903c-8d36ba757718",
   "metadata": {},
   "source": [
    "<a id='path'></a> \n",
    "## **Import Packages**\n",
    "\n",
    "As always, we begin by importing the necessary packages for our analysis. This tutorial assumes that you have all the packages needed for the [Plotting Regional Time Series](https://github.com/climate-datalab/EnsembleAnalysis/blob/main/2.%20Plotting%20Regional%20Time%20Series%20Using%20Shapefiles.ipynb) tutorial in the EnsembleAnalysis repo installed; if you need more details on these packages, please see that tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b4a239-851e-4c04-b70e-99346a6f669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/anaconda3/envs/eds296-stevenson/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import s3fs\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import Point\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b926a2e-d008-4bf0-834f-e99e513d4f10",
   "metadata": {},
   "source": [
    "<a id='load'></a> \n",
    "## **Load and Query the Cal-Adapt Catalog**\n",
    "\n",
    "Now we can use `intake` to load the information associated with the Cal-Adapt holdings on Amazon Web Services!\n",
    "\n",
    "For detailed background information on Cal-Adapt, see either:\n",
    "- [tutorial 1 in this repo](https://github.com/climate-datalab/Cal-Adapt-diagnostics/blob/677b41a18feb2bdd6fc2468a9aff23cc6652b781/1.%20Mapping%20Downscaled%20Products.ipynb)\n",
    "- [cal-adapt.org](http://cal-adapt.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e15e4e-4bfb-438e-be71-f65530c7e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Cal-Adapt data catalog, store as a variable\n",
    "catalog = intake.open_esm_datastore('https://cadcat.s3.amazonaws.com/cae-collection.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cca45-d0ff-44d4-81e3-96b7fa5896e8",
   "metadata": {},
   "source": [
    "Let's build on the activities we were working on in tutorial \"1. Mapping Downscaled Products\" in this repository. We were using the downscaled simulations from either LOCA2 or WRF, run with the CESM2, to visualize changes in precipitation under future warming scenarios. Now let's figure out how to extend that approach and add _wind vectors_ to the plot, so that we can see how patterns of atmospheric circulation might change as well!\n",
    "\n",
    "We can specify some of the necessary search terms in the catalog to extract that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7206a6e9-f953-4c22-96ef-57fc2c844984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify search terms to query catalog \n",
    "# activity_id: which downscaling technique do you want?\n",
    "activity_id = [\"WRF\"]\n",
    "\n",
    "# experiment_id: which historical/future scenario do you want?\n",
    "experiment_ids = [\"historical\", \"ssp370\"]\n",
    "\n",
    "# table_id: which time resolution do you want?\n",
    "table_id = [\"day\"]\n",
    "\n",
    "# source_id: which model do you want?\n",
    "source_id = [\"CESM2\"]\n",
    "\n",
    "# institution_id: which research institution do you want?\n",
    "institution_id = [\"UCSD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359af30-5f9f-4f31-986d-6a2c7331b5e6",
   "metadata": {},
   "source": [
    "The above specifies that we would like daily information for both the historical and future (SSP3-7.0) periods from CESM2; I've also gone ahead and stated that we'll use the WRF downscaling performed at UCSD (for this particular model, there are two options which use different coordinate names - that's something we can deal with, but for simplicity we'll just use one right now).\n",
    "\n",
    "Let's extract the catalog information for the above query, then see what variables are available to plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d1ac73-0910-46bd-9780-7585bef56ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prec' 'q2' 'rh_max' 'rh_min' 'sw_dwn' 't2max' 't2min' 'u10' 'v10'\n",
      " 'wspd10mean']\n"
     ]
    }
   ],
   "source": [
    "# Search through catalog, store results\n",
    "wrf_res = catalog.search(activity_id=activity_id, experiment_id=experiment_ids,\n",
    "                     table_id=table_id, source_id=source_id, institution_id=institution_id)\n",
    "\n",
    "# Create a data frame\n",
    "wrf_df = wrf_res.df\n",
    "\n",
    "# Plot variables available\n",
    "print(wrf_df.variable_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0b084-2779-43f8-a5e1-a852af62d08e",
   "metadata": {},
   "source": [
    "The first entry returned is the `prec` variable that's the WRF version of precipitation - we learned about how to work with that in the previous tutorial. \n",
    "\n",
    "The other two we'll want here are:\n",
    "- u10: the _east-west_ wind at an elevation of 10 meters;\n",
    "- v10: the _north-south_ wind at the same 10 meter elevation.\n",
    "\n",
    "If we extract both of those, we can use them to specify the x and y _components_ of our wind vector later on!\n",
    "\n",
    "Now that we have the full data frame for all the WRF information, we can extract the pieces of it that go with all our variables: there will be three in total this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e68d87-820c-41f5-b1ac-09d633640f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make data frames for just precip, zonal wind, and meridional wind\n",
    "prec_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"prec\")]\n",
    "u10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"u10\")]\n",
    "v10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"v10\")]\n",
    "\n",
    "# Display data frame associated with results\n",
    "#display(prec_cesm2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7dcde45-f331-4fb4-9b5f-f7d62aed7d94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define list of ensemble members\n",
    "# (in this case there's only one but that might not always be true)\n",
    "mems = [\"r11i1p1f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41ee8fc6-094a-482d-b8a1-cbb356e78582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r11i1p1f1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WRF</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>day</td>\n",
       "      <td>u10</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://cadcat/wrf/ucsd/cesm2/historical/r11i1p1f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_id institution_id source_id experiment_id  member_id table_id  \\\n",
       "7         WRF           UCSD     CESM2    historical  r11i1p1f1      day   \n",
       "\n",
       "  variable_id grid_label                                               path  \n",
       "7         u10        d03  s3://cadcat/wrf/ucsd/cesm2/historical/r11i1p1f...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Store HISTORICAL data as xarray\u001b[39;00m\n\u001b[1;32m     28\u001b[0m hist_prec \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(prec_cesm2df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], storage_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m---> 29\u001b[0m hist_u10 \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(\u001b[43mu10_cesm2df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, storage_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m     30\u001b[0m hist_v10 \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(v10_cesm2df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], storage_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Do the same thing for the SSP ensemble\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# precip\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eds296-stevenson/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Define an empty list\n",
    "cesm2_wrf_prec = []\n",
    "cesm2_wrf_u10 = []\n",
    "cesm2_wrf_v10 = []\n",
    "\n",
    "# Loop over all common ensemble members; leave the loop structure\n",
    "# so that we can change to using multiple members if need be\n",
    "for mem in range(len(mems)):\n",
    "    print(mems[mem])\n",
    "\n",
    "    # Extract HISTORICAL member of interest\n",
    "    # precip\n",
    "    prec_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"prec\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"historical\")\n",
    "                         & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "    # east-west wind\n",
    "    u10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"u10\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"historical\")\n",
    "                        & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "    # north-south wind\n",
    "    v10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"v10\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"historical\")\n",
    "                        & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "\n",
    "    display(u10_cesm2df)\n",
    "    \n",
    "    # Store HISTORICAL data as xarray\n",
    "    hist_prec = xr.open_zarr(prec_cesm2df['path'][0], storage_options={'anon': True})\n",
    "    hist_u10 = xr.open_zarr(u10_cesm2df['path'][0], storage_options={'anon': True})\n",
    "    hist_v10 = xr.open_zarr(v10_cesm2df['path'][0], storage_options={'anon': True})\n",
    "\n",
    "    # Do the same thing for the SSP ensemble\n",
    "    # precip\n",
    "    prec_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"prec\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"ssp370\")\n",
    "                         & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "    # east-west wind\n",
    "    u10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"u10\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"ssp370\")\n",
    "                        & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "    # north-south wind\n",
    "    v10_cesm2df = wrf_df[(wrf_df[\"variable_id\"] == \"v10\") \n",
    "                          & (wrf_df[\"experiment_id\"] == \"ssp370\")\n",
    "                        & (wrf_df[\"member_id\"] == mems[mem])]\n",
    "    \n",
    "     \n",
    "    # Store SSP3-7.0 data as xarray\n",
    "    ssp370_prec = xr.open_zarr(prec_cesm2df['path'][0], storage_options={'anon': True})\n",
    "    ssp370_u10 = xr.open_zarr(u10_cesm2df['path'][0], storage_options={'anon': True})\n",
    "    ssp370_v10 = xr.open_zarr(v10_cesm2df['path'][0], storage_options={'anon': True})\n",
    "    \n",
    "    # Concatenate historical, SSP information\n",
    "    prec_data = xr.concat([hist_prec, ssp_prec], dim=\"time\")\n",
    "    u10_data = xr.concat([hist_u10, ssp_u10], dim=\"time\")\n",
    "    v10_data = xr.concat([hist_v10, ssp_v10], dim=\"time\")\n",
    "    \n",
    "    # Add to list\n",
    "    cesm2_wrf_prec.append(prec_data)\n",
    "    cesm2_wrf_u10.append(u10_data)\n",
    "    cesm2_wrf_v10.append(v10_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f566294-19aa-407b-b3bb-52f4fbbab440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e386f-3191-467e-b4d0-f21ec50efba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate the list into a single xarray object\n",
    "cesm2_wrf_data = xr.concat(cesm2_wrf_data, dim=\"member\")\n",
    "\n",
    "# Store the actual member information as values of the new dimension\n",
    "cesm2_wrf_data = cesm2_wrf_data.assign_coords(member=(\"member\", common_mems))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS296)",
   "language": "python",
   "name": "eds196-stevenson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
